{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This note book runs the efficent model using the noisy students weights. We will use the features and fine tune it with our dataset.\n",
    "### we do not have enough data for training it from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import cv2\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import tensorboard\n",
    "SEEDS = 42\n",
    "np.random.seed(SEEDS)\n",
    "tf.random.set_seed(SEEDS)\n",
    "import itertools\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU= tf.config.list_physical_devices('CPU')\n",
    "print(\"Num GPUs:\", len(GPU))\n",
    "\n",
    "print(\"Num CPUs:\", len(CPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the memory growth incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The logical GPUs is not supported in the tensflow available binary, you need to compile it from scratch for multiple logical GPUs\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "      tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "      print(len(gpus), \"Physical GPUs,\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"efficientnetv2-xl-21k-ft1k\" # @param ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n",
    "\n",
    "model_handle_map = {\n",
    "  \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-xl-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/feature_vector/2\",\n",
    "  \"efficientnetv2-b0-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b3/feature_vector/2\",\n",
    "  \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-xl-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/feature_vector/2\",\n",
    "  \"efficientnetv2-b0-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/feature_vector/2\",\n",
    "  \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/feature_vector/2\",\n",
    "  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n",
    "  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n",
    "  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n",
    "  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n",
    "  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n",
    "  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n",
    "  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n",
    "  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n",
    "  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\",\n",
    "  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n",
    "  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n",
    "  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n",
    "  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n",
    "  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\",\n",
    "  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\",\n",
    "  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n",
    "  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n",
    "  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n",
    "  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n",
    "  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n",
    "  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"efficientnetv2-s\": 384,\n",
    "  \"efficientnetv2-m\": 480,\n",
    "  \"efficientnetv2-l\": 480,\n",
    "  \"efficientnetv2-b0\": 224,\n",
    "  \"efficientnetv2-b1\": 240,\n",
    "  \"efficientnetv2-b2\": 260,\n",
    "  \"efficientnetv2-b3\": 300,\n",
    "  \"efficientnetv2-s-21k\": 384,\n",
    "  \"efficientnetv2-m-21k\": 480,\n",
    "  \"efficientnetv2-l-21k\": 480,\n",
    "  \"efficientnetv2-xl-21k\": 512,\n",
    "  \"efficientnetv2-b0-21k\": 224,\n",
    "  \"efficientnetv2-b1-21k\": 240,\n",
    "  \"efficientnetv2-b2-21k\": 260,\n",
    "  \"efficientnetv2-b3-21k\": 300,\n",
    "  \"efficientnetv2-s-21k-ft1k\": 384,\n",
    "  \"efficientnetv2-m-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-l-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-xl-21k-ft1k\": 512,\n",
    "  \"efficientnetv2-b0-21k-ft1k\": 224,\n",
    "  \"efficientnetv2-b1-21k-ft1k\": 240,\n",
    "  \"efficientnetv2-b2-21k-ft1k\": 260,\n",
    "  \"efficientnetv2-b3-21k-ft1k\": 300, \n",
    "  \"efficientnet_b0\": 224,\n",
    "  \"efficientnet_b1\": 240,\n",
    "  \"efficientnet_b2\": 260,\n",
    "  \"efficientnet_b3\": 300,\n",
    "  \"efficientnet_b4\": 380,\n",
    "  \"efficientnet_b5\": 456,\n",
    "  \"efficientnet_b6\": 528,\n",
    "  \"efficientnet_b7\": 600,\n",
    "  \"inception_v3\": 299,\n",
    "  \"inception_resnet_v2\": 299,\n",
    "  \"nasnet_large\": 331,\n",
    "  \"pnasnet_large\": 331,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Input size {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "CLASS_NUM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining training dataset diredtories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,3.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_1= \"/home/pms/PMS-dataset/data-set/10-class/combined/training\"\n",
    "data_dir_2= \"/home/pms/PMS-dataset/data-set/10-class/output/training\"\n",
    "\n",
    "data_dir_1 = pathlib.Path(data_dir_1)\n",
    "data_dir_2 = pathlib.Path(data_dir_2)\n",
    "print(\"Training-Directory-combined: \",data_dir_1)\n",
    "print(\"Training-Directory-only-road: \",data_dir_1)\n",
    "\n",
    "\n",
    "image_count_1 = len(list(data_dir_1.glob('*/*.jpg')))\n",
    "image_count_2 = len(list(data_dir_2.glob('*/*.jpg')))\n",
    "print(image_count_1)\n",
    "print(image_count_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing dataset from the directory into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds_1 = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_dir_1),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=SEEDS,\n",
    "  image_size=IMAGE_SIZE,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_ds_2 = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_dir_2),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=SEEDS,\n",
    "  image_size=IMAGE_SIZE,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "val_ds_1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  str(data_dir_1),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=SEEDS,\n",
    "  image_size=IMAGE_SIZE,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds_2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  str(data_dir_2),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=SEEDS,\n",
    "  image_size=IMAGE_SIZE,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "class_names = np.array(train_ds_1.class_names)\n",
    "print(class_names)\n",
    "class_names = np.array(train_ds_2.class_names)\n",
    "print(class_names)\n",
    "class_names_val = np.array(val_ds_1.class_names)\n",
    "print(class_names_val)\n",
    "class_names_val = np.array(val_ds_2.class_names)\n",
    "print(class_names_val)\n",
    "#concatenate the datasets\n",
    "train_ds = train_ds_1.concatenate(train_ds_2)\n",
    "val_ds = val_ds_1.concatenate(val_ds_2)\n",
    "\n",
    "print(len(list(train_ds_1.as_numpy_iterator())))\n",
    "print(len(list(train_ds_2.as_numpy_iterator())))\n",
    "print(len(list(train_ds.as_numpy_iterator())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Data augmentation to the training set and rescaling the images to 0-1 in both training and validation set and autotune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomFlip('vertical'),\n",
    "  tf.keras.layers.RandomRotation(2),\n",
    "  tf.keras.layers.RandomZoom(.5),\n",
    "  tf.keras.layers.RandomContrast(0.1, 0.2)\n",
    "])\n",
    "# apply normalization and augmentation to the training set and validation set\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "## WARNING: the rescaling layer is not applied if uisng keras EfficientNet application model not in tensorhub model\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# check the batch size\n",
    "image_batch, label_batch = next(iter(train_ds.take(1)))\n",
    "print(image_batch.shape, label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for debugging purpose\n",
    "#tf.debugging.set_log_device_placement(True) # this line is to turn on debugging information\n",
    "\n",
    "train_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1) # Enable histogram computation for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "    do_fine_tuning = False\n",
    "\n",
    "    print(\"Building model with\", model_handle)\n",
    "    model = tf.keras.Sequential([\n",
    "        # Explicitly define the input shape so the model can be properly\n",
    "        # loaded by the TFLiteConverter\n",
    "        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "        hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        #tf.keras.layers.Dense(CLASS_NUM,kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "        tf.keras.layers.Dense(CLASS_NUM,kernel_regularizer=tf.keras.regularizers.l2(0.0001),activation='softmax')\n",
    "    ])\n",
    "    model.build((None,)+IMAGE_SIZE+(3,))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "  base_learning_rate = 0.01\n",
    "## choose the optimizer uncomment the one you want\n",
    "\n",
    "  #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "  #              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  #              metrics=['accuracy'])\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "    NUM_EPOCHS = 1\n",
    "# class weight are calculated by the total of samples divided by the number of classes and the number of samples in each class\n",
    "    class_weights = {0: 0.85,1 : 0.83,2 : 1.495,3 : 1.57,4 : 2.153,5 : 2.53,6 : 1.17,7 : 0.89,8 : 0.609,9 : 0.54}\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=tensorboard_callback,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "  base_learning_rate = 0.001\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "  NUM_EPOCHS = 200\n",
    "  history = model.fit(\n",
    "          train_ds,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=tensorboard_callback,\n",
    "          class_weight=class_weights)\n",
    "\n",
    "plot_hist(history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = model\n",
    "with tf.device('device:GPU:0'):\n",
    "  test_data_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/training')\n",
    "  print(test_data_dir)\n",
    "  img_height = pixels\n",
    "  img_width = pixels\n",
    "  batch_size = 8\n",
    "  class_number = CLASS_NUM\n",
    "\n",
    "  test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "    # normalize the images is necessary for models in keras-tensorflow-hub\n",
    "  test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "  loss, accuracy = reloaded.evaluate(test_dataset)\n",
    "  print('Test accuracy :', accuracy)\n",
    "  print('Test loss :', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pms_model/tensoflow-class-10-efficientnetv2-xl-21k-ft1k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "  \n",
    "# Workbook is created\n",
    "wb = Workbook()\n",
    "# add_sheet is used to create sheet.\n",
    "test = wb.add_sheet('Test-road-Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "    result_test_data_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/testing')\n",
    "    output_test_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/results/output_test-efficientnetv2-xl-21k-ft1k-with-weight')\n",
    "    try:\n",
    "        os.makedirs(output_test_dir, exist_ok=True)\n",
    "        print(\"Directory created\")\n",
    "    except OSError as e:\n",
    "        print(\"Directory already exists\")\n",
    "count = 0\n",
    "countf = 0\n",
    "countF = 0\n",
    "countT = 0\n",
    "count_loop = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "count5 = 0\n",
    "count6 = 0\n",
    "count7 = 0\n",
    "count8 = 0\n",
    "count9 = 0\n",
    "count10 = 0\n",
    "\n",
    "root, class_n, files = next(os.walk(result_test_data_dir))\n",
    "print(class_n)\n",
    "for c in class_n:\n",
    "    new_root = os.path.join(output_test_dir, c)\n",
    "    try:\n",
    "        os.mkdir(new_root)\n",
    "    except OSError as e:\n",
    "        print(\"Directory already exists\")\n",
    "    for dirs in os.walk(os.path.join(root, c)):\n",
    "        for files in dirs:\n",
    "            for filename in files:\n",
    "                if(filename.endswith(\".jpg\")):\n",
    "                    path = os.path.join(root, c, filename)\n",
    "                    #img = tf.keras.utils.load_img(path, target_size=(img_height, img_width))\n",
    "                    orig = cv2.imread(path)\n",
    "                    img = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (img_height, img_width))\n",
    "                    img_array = tf.keras.utils.img_to_array(img)\n",
    "                    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "                    img_array = normalization_layer(img_array)\n",
    "                    with tf.device('device:GPU:0'):\n",
    "                        predictions = reloaded.predict(img_array)\n",
    "                        score = tf.nn.softmax(predictions[0])\n",
    "                    if (int(class_names[np.argmax(score)])==int(c)):\n",
    "                        count=count+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==10):\n",
    "                        countf=countf+1\n",
    "                        count10=count10+1\n",
    "                    elif(int(class_names[np.argmax(score)])==9):\n",
    "                        countf=countf+1\n",
    "                        count9=count9+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==8):\n",
    "                        countf=countf+1\n",
    "                        count8=count8+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==7):\n",
    "                        countf=countf+1\n",
    "                        count7=count7+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==6):\n",
    "                        countf=countf+1\n",
    "                        count6=count6+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==5):\n",
    "                        countf=countf+1\n",
    "                        count5=count5+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==4):\n",
    "                        countf=countf+1\n",
    "                        count4=count4+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==3):\n",
    "                        countf=countf+1\n",
    "                        count3=count3+1\n",
    "                    elif(int(class_names[np.argmax(score)])==2):\n",
    "                        countf=countf+1\n",
    "                        count2=count2+1\n",
    "                    elif(int(class_names[np.argmax(score)])==1):\n",
    "                        countf=countf+1\n",
    "                        count1=count1+1\n",
    "                    else:\n",
    "                        print('error')\n",
    "                    new_filename = filename.split(\".\")[0]+ filename.split(\".\")[1] + \"_\" + \"P_\" + str(int(class_names[np.argmax(score)])) + \".jpg\"\n",
    "                    new_path = os.path.join(new_root, new_filename)\n",
    "                    cv2.imwrite(new_path, orig)\n",
    "                    #print(new_filename )\n",
    "    countT = countT + count\n",
    "    countF = countF + countf\n",
    "    print('=========================================================')\n",
    "    print('class: ',c, 'Images: ',len(files), 'TP: ', count/len(files), 'FP: ',countf/len(files))\n",
    "    #print('one : ',count1/len(files),'two: ',count2/len(files),'three: ',count3/len(files),'four: ',count4/len(files),'five: ',count5/len(files),'six: ',count6/len(files),'seven: ',count7/len(files),'eight: ',count8/len(files),'nine: ',count9/len(files),'ten: ',count10/len(files))\n",
    "    print('one: ',count1,'two: ',count2,'three: ',count3,'four: ',count4,'five: ',count5,'six: ',count6,'seven: ',count7,'eight: ',count8,'nine: ',count9,'ten: ',count10)\n",
    "    test.write(int(c), 1, count1)\n",
    "    test.write(int(c), 2, count2)\n",
    "    test.write(int(c), 3, count3)\n",
    "    test.write(int(c), 4, count4)\n",
    "    test.write(int(c), 5, count5)\n",
    "    test.write(int(c), 6, count6)\n",
    "    test.write(int(c), 7, count7)\n",
    "    test.write(int(c), 8, count8)\n",
    "    test.write(int(c), 9, count9)\n",
    "    test.write(int(c), 10, count10)\n",
    "    test.write(int(c), 11, count)\n",
    "    test.write(int(c), 12, countf)\n",
    "\n",
    "    count = 0\n",
    "    countf = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    count5 = 0\n",
    "    count6 = 0\n",
    "    count7 = 0\n",
    "    count8 = 0\n",
    "    count9 = 0\n",
    "    count10 = 0\n",
    "    count_loop = count_loop + 1\n",
    "print('Total classes: ',count_loop,'Total TP: ', countT/(countT+countF), 'Total FP: ',countF)\n",
    "test.write(11, 0, countT/(countT+countF))\n",
    "test.write(11, 1, countF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save('tenclass-road-efficientnetv2-xl-21k-ft1k-with-weight.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workbook is created\n",
    "wb2 = Workbook()\n",
    "# add_sheet is used to create sheet.\n",
    "test2 = wb2.add_sheet('Test-Summary-road')\n",
    "test2.write(0,0,'No')\n",
    "test2.write(0,1,'filename')\n",
    "test2.write(0,2,'true-class')\n",
    "test2.write(0,3,'predicted-class')\n",
    "iter = 1\n",
    "\n",
    "with tf.device('device:GPU:0'):\n",
    "    result_test_data_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/testing')\n",
    "    #result_test_data_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/5-class/output/testing')\n",
    "    output_test_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/results/test')\n",
    "    #output_test_dir = pathlib.Path('/home/pms/PMS-dataset/data-set/10-class/output/results/test')\n",
    "    try:\n",
    "        os.makedirs(output_test_dir, exist_ok=True)\n",
    "        print(\"Directory created\")\n",
    "    except OSError as e:\n",
    "        print(\"Directory already exists\")\n",
    "count = 0\n",
    "countf = 0\n",
    "countF = 0\n",
    "countT = 0\n",
    "count_loop = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "count5 = 0\n",
    "\n",
    "root, class_n, files = next(os.walk(result_test_data_dir))\n",
    "print(class_n)\n",
    "for c in class_n:\n",
    "    new_root = os.path.join(output_test_dir, c)\n",
    "    try:\n",
    "        os.mkdir(new_root)\n",
    "    except OSError as e:\n",
    "        print(\"Directory already exists\")\n",
    "    for dirs in os.walk(os.path.join(root, c)):\n",
    "        for files in dirs:\n",
    "            for filename in files:\n",
    "                if(filename.endswith(\".jpg\")):\n",
    "                    path = os.path.join(root, c, filename)\n",
    "                    #img = tf.keras.utils.load_img(path, target_size=(img_height, img_width))\n",
    "                    orig = cv2.imread(path)\n",
    "                    img = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (img_height, img_width))\n",
    "                    img_array = tf.keras.utils.img_to_array(img)\n",
    "                    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "                    img_array = normalization_layer(img_array)\n",
    "                    \n",
    "                    predictions = reloaded.predict(img_array)\n",
    "                    score = tf.nn.softmax(predictions[0])\n",
    "                    ## write to excel------------------------------------\n",
    "                    test2.write(iter, 0, iter)\n",
    "                    test2.write(iter, 1, filename)\n",
    "                    test2.write(iter, 2, int(c))\n",
    "                    test2.write(iter, 3, int(class_names[np.argmax(score)]))\n",
    "                    iter = iter + 1 # this iterator is for serial number in excel file to count number of jpg files\n",
    "                        #-----------------------------------------------------\n",
    "                    if (int(class_names[np.argmax(score)])==int(c)):\n",
    "                        count=count+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==5):\n",
    "                        countf=countf+1\n",
    "                        count5=count5+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==4):\n",
    "                        countf=countf+1\n",
    "                        count4=count4+1\n",
    "                    elif(int(class_names[np.argmax(score)]) ==3):\n",
    "                        countf=countf+1\n",
    "                        count3=count3+1\n",
    "                    elif(int(class_names[np.argmax(score)])==2):\n",
    "                        countf=countf+1\n",
    "                        count2=count2+1\n",
    "                    elif(int(class_names[np.argmax(score)])==1):\n",
    "                        countf=countf+1\n",
    "                        count1=count1+1\n",
    "                    elif(int(class_names[np.argmax(score)])==6):\n",
    "                        countf=countf+1\n",
    "                        count6=count6+1\n",
    "                    elif(int(class_names[np.argmax(score)])==7):\n",
    "                        countf=countf+1\n",
    "                        count7=count7+1\n",
    "                    elif(int(class_names[np.argmax(score)])==8):\n",
    "                        countf=countf+1\n",
    "                        count8=count8+1\n",
    "                    elif(int(class_names[np.argmax(score)])==9):\n",
    "                        countf=countf+1\n",
    "                        count9=count9+1\n",
    "                    elif(int(class_names[np.argmax(score)])==10):\n",
    "                        countf=countf+1\n",
    "                        count10=count10+1\n",
    "                    else:\n",
    "                        print('error')\n",
    "                    new_filename = filename.split(\".\")[0]+ filename.split(\".\")[1] + \"_\" + \"P_\" + str(int(class_names[np.argmax(score)])) + \".jpg\"\n",
    "                    new_path = os.path.join(new_root, new_filename)\n",
    "                    cv2.imwrite(new_path, orig)\n",
    "                    #print(new_filename )\n",
    "\n",
    "    countT = countT + count\n",
    "    countF = countF + countf\n",
    "    print('=========================================================')\n",
    "    print('class: ',c, 'Images: ',len(files), 'TP: ', count/len(files), 'FP: ',countf/len(files))\n",
    "    print('one: ',count1,'two: ',count2,'three: ',count3,'four: ',count4,'five: ',count5)\n",
    "\n",
    "    count = 0\n",
    "    countf = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    count5 = 0\n",
    "    count6 = 0\n",
    "    count7 = 0\n",
    "    count8 = 0\n",
    "    count9 = 0\n",
    "    count10 = 0\n",
    "    count_loop = count_loop + 1\n",
    "print('Total classes: ',count_loop,'Total TP: ', countT/(countT+countF), 'Total FP: ',countF)\n",
    "\n",
    "wb2.save('road-10-classes.xls')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae85714aaa4675f82ee9f7fc78406fe72191dfc57a9d1ac25f5187021de0688d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('waqar-tf-latest': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
